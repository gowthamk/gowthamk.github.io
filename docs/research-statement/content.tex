The evolution of computational systems has always trended in the direction
of increasing complexity. While early machines were designed for simple
sequential computations, modern computational systems routinely operate
concurrently in distributed environments connected by adversarial and
unreliable networks. Ensuring safety and security of distributed
computational systems requires novel programming abstractions and formal
(reasoning) methods that enable programmers overcome the overwhelming
complexity inherent to the design of these systems. 
\begin{mdquote}
My research attempts to make foundational advances in programming languages
and formal methods with aim of making provably-safe distributed systems
development accessible to mainstream software developers.
\end{mdquote}
\noindent Formal methods have seen increasing adoption in mission-critical
systems in the recent years. DARPA's HACMS program, for example,
demonstrated the effectiveness of formal verification in securing unmanned
aerial vehicles~\cite{darpa-hacms}. However, their widespread adoption
remains a challenge due to the steep learning curve, integration
complexity, and scalability concerns associated with formal methods.
Bridging the gap between theoretical advances and practical deployment in
industry requires research into more accessible tools, automated reasoning
techniques, and programming abstractions that can seamlessly integrate with
existing development workflows. My work is motivated by these challenges
and aims to make formal methods more practical and impactful for real-world
software systems. My research program involves three major thrusts,
numbered $R_{1-3}$, to address scalability, generality, and usability
challenges associated with formal methods. I will next summarize each
research thrust, highlight significant contributions, and present their
broader impacts and applications. 

\section*{$R_1$ Scaling Formal Verification to Real Systems}

Programming safe and reliable distributed systems is extremely
hard~\cite{aws-formal,samc,Yu2018}. The complexity stems from having to
simultaneously reason about several failure modes, such as reordered and
dropped messages, network partitions, and node crashes. Complex
combinatorial reasoning involving low-level events and high-level
application logic is hard for humans and machines alike, making it
challenging to apply formal methods at scale. Consequently, formal
certification of safety and reliability guarantees of distributed systems
remains out of reach for most application developers. Any formal
verification that is currently done in the industry is carried out at the
level of distributed protocol specifications, e.g., using TLA+~\cite{tla}
or P~\cite{p-lang}, with no way to translate the guarantees to
implementations.

Several decades of research into programming languages has shown that
modularity and abstraction is often the key to overcoming programming
complexity. The abstractions typically used to program distributed systems
today expose asynchronous communication primitives and require the explicit
reasoning about the dynamics of the network state in relation to faults. To
scale formal verification to real-world systems implementations, we need
novel programming abstractions that decompose the complexity of fault
tolerance and protocol logic into loosely-coupled \emph{modules} and
\emph{services} amenable to independent specification and verification.

\begin{mdquote}
Thrust 1 focuses on developing novel programming abstractions that enable
modular specification, verification, and implementation of distributed systems.
\end{mdquote}

The primary motivation for modular decomposition in our case is automated
verification as opposed to efficient implementation. To be amenable to
SMT-aided automated reasoning, verification conditions should be encodable
in a a decidable logic, which requires deliberate design of modules and
interfaces. As a part of ongoing work in Thrust 1, we are developing
language-embedded specification and reasoning frameworks that reduce the
manual effort and creative inputs involved in this process. The broadest
impact will be on mainstream application programmers, who may not have the
expertise to build mission-critical distributed systems. Our research will
help programmers overcome the complexity of this task by making formal
verification and machine-assisted reasoning readily accessible. 

\mypara{Significant Contributions} Our early work in Thrust
1~\cite{mrdt, snapl19, quark} focused on development of \emph{Mergeable
Replicated Data Types} (MRDTs) -- a high-level distributed programming
abstraction that guarantees fault tolerance by design. We built a
distributed runtime for MRDTs, called \quark~\cite{quark}, that
orchestrates distributed computation in a way that is guaranteed to
converge. This is in contrast to the state-of-the-art RDT abstractions,
which require the programmer to prove the convergence of a computation
explicitly~\cite{crdt}. \quark has allowed us to uncover novel performance
tradeoffs in distributed applications and collect strong experimental
evidence demonstrating the viability of high-level programming abstractions
for \emph{coordination-free} distributed computations. Theoretically, RDTs
are a high-level abstraction of a weakly-consistent replicated state
machine (RSM), denoted $\eventual$ RSM. While $\eventual$ RSMs are often
useful, safety-critical distributed systems need strongly-consistent
($\strong$) RSMs, whose implementations are known to be notoriously
complex. In our recent work~\cite{lewchenko-oopsla25}, we have shown that
$\eventual$ RSMs can be extended with modules of inter-replica coordination
to obtain $\strong$ RSMs, resulting in a modular approach that drastically
reduced the overhead of safety verification. We implemented this technique
in a verification framework called \superv and used it to automatically
verify an industry-strength implementation of Raft log replication
protocol~\cite{raft}. We believe this is a notable achievement considering
that verification efforts of similar nature required 2-3 orders of
magnitude more manual annotations~\cite{VerdiRaft}. Our results will soon
be presented at SIGPLAN OOPSLA 2025 conference. 

\mypara{Funding and Project Management} The primary source of funding has
thus far been my startup grant. An Amazon Research Award providing \$50,000
to this work had to be declined on insistence of CU's office of contracts
and grants (OCG). An NSF Small proposal titled \emph{A  Modular Approach to
Practical Distributed Systems VeriÔ¨Åcation} is currently pending review. The
proposed budget is \$480,110 to be spent over three years. The project team
includes Mr. Nicholas Lewchenko, a PhD student advised by me. Mr. Lewchenko
will graduate in Spring 2026 and will be replaced by a new graduate student
yet to be admitted. 

\section*{$R_2$ Generalizing Formal Verification to Adversarial Networks}

Like the prior work on distributed systems verification~\cite{verdi,
VerdiRaft, disel-popl18}, Thrust 1 focuses on \emph{crash faults} such as
node crashes and network partitions. In conventional data center-based
deployments, exceptional behavior is almost exclusively due to crash
faults. However, distributed systems now increasingly operate the public
internet, where they are used to implement novel decentralized
applications, such as blockchain
cryptocurrencies~\cite{nakamoto-bitcoin08,buterin-eth14} and federated
social networks~\cite{mastodon,bluesky}. A decentralized application is
effectively a distributed protocol designed to operate on a public network.
The early successes of decentralized applications and the push towards
local-first software~\cite{local-first} are expected to accelerate the
development of a novel class of distributed protocols designed to execute
on internet-native distributed systems. While network partitions remain a
major concern on public networks,  more serious concern is the presence of
adversaries who can actively subvert protocol executions towards unsafe or
unproductive states \emph{even} when all the protocol participants are
honest (i.e., non-byzantine). Ensuring the safety of distributed systems
and the privacy of their users on adversarial networks requires
synthesizing reasoning and verification techniques from Cryptography and
Distributed Systems.
\begin{mdquote}
  The focus of Thrust 2 is to develop a unified framework that combines cryptographic proofs of security with formal verification of distributed protocols. 
\end{mdquote}
\noindent The goal is to help developers obtain strong guarantees of safety
and privacy in adversarial environments. Like in Thrust 1, we seek modular
abstractions that allow compositional specification and verification of
protocol components, but now with explicit modeling of adversarial actions
and cryptographic primitives. In our ongoing work, we are developing
frameworks that enable automated reasoning about both protocol correctness
and cryptographic soundness, aiming to reduce the manual effort required
for end-to-end verification. This approach will empower developers to build
robust decentralized applications that are resilient to both crash faults
and active attacks, facilitating broader adoption of secure distributed
systems in practice.

\mypara{Significant Contributions} In~\cite{waldo-oopsla23}, we introduced
a novel formal model of cryptography and an associated probablistic
relational verification framework. In formal verification of cryptographic
protocols, a network attacker is modeled in one of the two fundamentally
different ways: (a). a \emph{symbolic} or \emph{Dolev-Yao} attacker defined
in terms of what the attacker can do~\cite{dolev-yao}, and (b). a
\emph{computational} attacker defined in terms of what the attacker can not
do~\cite{blanchet-tr23, bellare-eurocrypt06}. Correspondingly, two standard
models of cryptography -- \emph{Symbolic} and \emph{Computational} -- have
emerged. While the former is simpler and amenable to symbolic reasoning, it
underapproximates attacker capabilities, hence misses several classes of
attacks. Conversely, the latter is more general and precise, but requires
arduous manual proofs. In~\cite{waldo-oopsla23}, we introduced a
probabilistic model of cryptography that combines the strengths of both: it
is more precise than the symbolic model (hence covers more classes of
attacks) and more amenable to automation than the computational model. We
implemented the probabilistic model in an SMT-aided verification framework
called \waldo. \waldo is released publicly with an open source license, and
was used to identify subtle privacy issues in the draft proposal for TLS
Encrypted Client Hello (ECH) extension~\cite{ech-draft}. We believe this is
a significant milestone considering that TLS is the protocol powering
secure HTTP connections for the entire internet, hence any privacy issues
are bound to have adverse consequences. 

\mypara{Funding and Project Management} The primary source of funding has
thus far been my startup grant. My NSF CAREER proposal titled
\emph{Verifying Safety and Privacy of Distributed Systems on Adversarial
Networks} is currently under review. The proposed budget is \$714,519 to be
spent over five years for the activities in Thrust 2. In addition, we have
partnered with Psiphon Inc~\cite{psiphon} to provide inputs to DARPA PM Mr.
Michael Lack on formulating a new program on privacy verification on
internet. The project team includes PhD students Mr. Kirby Linvill and Mr.
Sai Aka, both advised by me. 

\section*{$R_3$ Making Formal Verification Accessible to Non-Experts}

A  significant progress has been made in the formal methods community
towards automating symbolic reasoning for complex systems. However, the
tools and languages developed often require a specialized skill set to
write precise mathematical specifications and proofs, which is often out of
reach for mainstream application programmers. To make formal methods an
accessible and routine part of the software development lifecycle, there is
a need for novel techniques and tools that flatten the learning curve and
lower the barrier to entry. The recent progress in Large Language Models
(LLMs) provides an exciting opportunity to (a). leverage natural languages
as interfaces to formal verification tools, and (b). use generative AI to
guide the proof search process. There are also notable new inventions in
programming language techniques, such as the Incorrectness Logic and
Goal-directed abstract abstract interpretation, which require minimal user
inputs to drive formal verification. In Thrust 3, our goal is to leverage
these developments to drastically improve the usability of formal methods,
particularly in the context of distributed systems. 
\begin{mdquote}
Thrust 3 focuses on developing symbolic and neuro-symbolic reasoning
techniques to automate formal verification for distributed systems. 
\end{mdquote}

\mypara{Significant Contributions} In~\cite{lewchenko-oopsla26}, we
proposed a novel partial-function semantics for higher-order functional
programs that makes them amenable to decidable encoding in SMT solvers.
Partial functions underapproximate total functions, which makes formal
verification unsound in general. Our key contribution is a set of
sufficient conditions under which the underapproximation is actually sound.
We developed a language extension to Rust, called $\lepr$, that lets
non-expert programmers use SMT solvers to automatically verify deep
semantic properties of higher-order functional programs. Another notable
contribution is the \dissprove verification
framework~\cite{fontenot-dissprove} for distributed protocols that
leverages a novel goal-directed backwards analysis we introduced in our
earlier work~\cite{meier-oopsla23} to eliminate the need for inductive
invariants (for a class of protocols). Identifying the right inductive
invariants is often hardest step in formal verification of distributed
protocols~\cite{ivy2016}. By short-circuiting this process, \dissprove
makes it feasible for non-experts to build provably-safe distributed
systems.

\mypara{Ongoing Work} In the above, we have only considered systems with
discrete dynamics. Our ongoing work extends formal verification to systems
with continuous dynamics where state transitions are defined in terms of
ordinary differential equations (ODEs). The complex structure of the ODEs
often makes it expensive to perform computations such as simulations and
probabilistic inference. In our ongoing work, we are building a DSL for
probabilistic programming with ODEs coupled with a verified optimizing
compiler. The compiler orchestrates a series of semantics-preserving
transformations, such as latent variable elimination, to automatically
transform ODEs into a form amenable to efficient inference. This allows
domain experts to focus on specifying system dynamics without concerning
themselves with efficient implementations. In another thread of ongoing
work, we showed that purely neural approaches, including the
state-of-the-art LLMs, perform poorly on program synthesis
tasks~\cite{roberson-arxiv2024}. To improve the effectiveness of LLM-driven
program synthesis, we designed a semantics-constrained decoding technique
that uses conventional symbolic techniques to prune unproductive inference
paths. The early results are promising and we are working on developing a
stand-alone tool to apply our insights at scale. 

\mypara{Funding and Project Management} The verified ODE transformation
work is funded by the NSF Formal Methods in the Field (FMitF) program from
09/01/2024 to 08/31/2028 through award number: 2422136, amount: \$875,000,
titled: \emph{FMitF: Track I: Verified Probabilistic Programming for Hybrid
Systems}. An Amazon Research Awards (ARA) proposal titled \emph{Program
Synthesis with Syntax-Aligned Language Models} is currently under review.
The project team includes Mr. Oscar Bender-Stone, an undergraduate student
on Discovery Learning Apprenticeship (DLA) program, along with the PhD
students Mr. Christian Fontenot, Mr. Nicholas Lewchenko, Mr. Kirby Linvill,
and Ms. Manasvi Parekh. 



